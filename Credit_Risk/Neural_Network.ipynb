{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"credit.pkl\",\"rb\") as f:\n",
    "    X_credit_training, y_credit_training, X_credit_test, y_credit_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.46116479\n",
      "Iteration 2, loss = 0.34639034\n",
      "Iteration 3, loss = 0.32333264\n",
      "Iteration 4, loss = 0.31084385\n",
      "Iteration 5, loss = 0.30112109\n",
      "Iteration 6, loss = 0.29212245\n",
      "Iteration 7, loss = 0.28489636\n",
      "Iteration 8, loss = 0.27796501\n",
      "Iteration 9, loss = 0.27313915\n",
      "Iteration 10, loss = 0.26817512\n",
      "Iteration 11, loss = 0.26431710\n",
      "Iteration 12, loss = 0.26203537\n",
      "Iteration 13, loss = 0.25989075\n",
      "Iteration 14, loss = 0.25710980\n",
      "Iteration 15, loss = 0.25560725\n",
      "Iteration 16, loss = 0.25308861\n",
      "Iteration 17, loss = 0.25152237\n",
      "Iteration 18, loss = 0.25048129\n",
      "Iteration 19, loss = 0.24920867\n",
      "Iteration 20, loss = 0.24785527\n",
      "Iteration 21, loss = 0.24654694\n",
      "Iteration 22, loss = 0.24562249\n",
      "Iteration 23, loss = 0.24510748\n",
      "Iteration 24, loss = 0.24364184\n",
      "Iteration 25, loss = 0.24260357\n",
      "Iteration 26, loss = 0.24223394\n",
      "Iteration 27, loss = 0.24102539\n",
      "Iteration 28, loss = 0.24025785\n",
      "Iteration 29, loss = 0.23970814\n",
      "Iteration 30, loss = 0.23862664\n",
      "Iteration 31, loss = 0.23877063\n",
      "Iteration 32, loss = 0.23784627\n",
      "Iteration 33, loss = 0.23702985\n",
      "Iteration 34, loss = 0.23648686\n",
      "Iteration 35, loss = 0.23576346\n",
      "Iteration 36, loss = 0.23478272\n",
      "Iteration 37, loss = 0.23459751\n",
      "Iteration 38, loss = 0.23429143\n",
      "Iteration 39, loss = 0.23303330\n",
      "Iteration 40, loss = 0.23295653\n",
      "Iteration 41, loss = 0.23239831\n",
      "Iteration 42, loss = 0.23225864\n",
      "Iteration 43, loss = 0.23147020\n",
      "Iteration 44, loss = 0.23050893\n",
      "Iteration 45, loss = 0.23020874\n",
      "Iteration 46, loss = 0.23009801\n",
      "Iteration 47, loss = 0.22939761\n",
      "Iteration 48, loss = 0.22911674\n",
      "Iteration 49, loss = 0.22873483\n",
      "Iteration 50, loss = 0.22846239\n",
      "Iteration 51, loss = 0.22799721\n",
      "Iteration 52, loss = 0.22738297\n",
      "Iteration 53, loss = 0.22728081\n",
      "Iteration 54, loss = 0.22713518\n",
      "Iteration 55, loss = 0.22679738\n",
      "Iteration 56, loss = 0.22620332\n",
      "Iteration 57, loss = 0.22583582\n",
      "Iteration 58, loss = 0.22556255\n",
      "Iteration 59, loss = 0.22561734\n",
      "Iteration 60, loss = 0.22503842\n",
      "Iteration 61, loss = 0.22488816\n",
      "Iteration 62, loss = 0.22501877\n",
      "Iteration 63, loss = 0.22417386\n",
      "Iteration 64, loss = 0.22436815\n",
      "Iteration 65, loss = 0.22375546\n",
      "Iteration 66, loss = 0.22369127\n",
      "Iteration 67, loss = 0.22350237\n",
      "Iteration 68, loss = 0.22370280\n",
      "Iteration 69, loss = 0.22320652\n",
      "Iteration 70, loss = 0.22288763\n",
      "Iteration 71, loss = 0.22269722\n",
      "Iteration 72, loss = 0.22222296\n",
      "Iteration 73, loss = 0.22201015\n",
      "Iteration 74, loss = 0.22155749\n",
      "Iteration 75, loss = 0.22174476\n",
      "Iteration 76, loss = 0.22177831\n",
      "Iteration 77, loss = 0.22131087\n",
      "Iteration 78, loss = 0.22088972\n",
      "Iteration 79, loss = 0.22052037\n",
      "Iteration 80, loss = 0.22083250\n",
      "Iteration 81, loss = 0.22054308\n",
      "Iteration 82, loss = 0.22010958\n",
      "Iteration 83, loss = 0.22016829\n",
      "Iteration 84, loss = 0.22032063\n",
      "Iteration 85, loss = 0.21952625\n",
      "Iteration 86, loss = 0.21984840\n",
      "Iteration 87, loss = 0.21939548\n",
      "Iteration 88, loss = 0.21921378\n",
      "Iteration 89, loss = 0.21959659\n",
      "Iteration 90, loss = 0.21916309\n",
      "Iteration 91, loss = 0.21892787\n",
      "Iteration 92, loss = 0.21857404\n",
      "Iteration 93, loss = 0.21863224\n",
      "Iteration 94, loss = 0.21807768\n",
      "Iteration 95, loss = 0.21794211\n",
      "Iteration 96, loss = 0.21774750\n",
      "Iteration 97, loss = 0.21847242\n",
      "Iteration 98, loss = 0.21757507\n",
      "Iteration 99, loss = 0.21774905\n",
      "Iteration 100, loss = 0.21728504\n",
      "Iteration 101, loss = 0.21675898\n",
      "Iteration 102, loss = 0.21715847\n",
      "Iteration 103, loss = 0.21660622\n",
      "Iteration 104, loss = 0.21698783\n",
      "Iteration 105, loss = 0.21617236\n",
      "Iteration 106, loss = 0.21611730\n",
      "Iteration 107, loss = 0.21624272\n",
      "Iteration 108, loss = 0.21605883\n",
      "Iteration 109, loss = 0.21567553\n",
      "Iteration 110, loss = 0.21550827\n",
      "Iteration 111, loss = 0.21557574\n",
      "Iteration 112, loss = 0.21495470\n",
      "Iteration 113, loss = 0.21478653\n",
      "Iteration 114, loss = 0.21478865\n",
      "Iteration 115, loss = 0.21419126\n",
      "Iteration 116, loss = 0.21469086\n",
      "Iteration 117, loss = 0.21392024\n",
      "Iteration 118, loss = 0.21384680\n",
      "Iteration 119, loss = 0.21408206\n",
      "Iteration 120, loss = 0.21363980\n",
      "Iteration 121, loss = 0.21380257\n",
      "Iteration 122, loss = 0.21358578\n",
      "Iteration 123, loss = 0.21317861\n",
      "Iteration 124, loss = 0.21315106\n",
      "Iteration 125, loss = 0.21255186\n",
      "Iteration 126, loss = 0.21263366\n",
      "Iteration 127, loss = 0.21248789\n",
      "Iteration 128, loss = 0.21240159\n",
      "Iteration 129, loss = 0.21251699\n",
      "Iteration 130, loss = 0.21161593\n",
      "Iteration 131, loss = 0.21218526\n",
      "Iteration 132, loss = 0.21174296\n",
      "Iteration 133, loss = 0.21196818\n",
      "Iteration 134, loss = 0.21194357\n",
      "Iteration 135, loss = 0.21136435\n",
      "Iteration 136, loss = 0.21114986\n",
      "Iteration 137, loss = 0.21121874\n",
      "Iteration 138, loss = 0.21115882\n",
      "Iteration 139, loss = 0.21100917\n",
      "Iteration 140, loss = 0.21062400\n",
      "Iteration 141, loss = 0.21084779\n",
      "Iteration 142, loss = 0.21017612\n",
      "Iteration 143, loss = 0.21044280\n",
      "Iteration 144, loss = 0.21004899\n",
      "Iteration 145, loss = 0.20984899\n",
      "Iteration 146, loss = 0.20998280\n",
      "Iteration 147, loss = 0.21008705\n",
      "Iteration 148, loss = 0.20977947\n",
      "Iteration 149, loss = 0.20945738\n",
      "Iteration 150, loss = 0.21003027\n",
      "Iteration 151, loss = 0.21003662\n",
      "Iteration 152, loss = 0.20954658\n",
      "Iteration 153, loss = 0.20947221\n",
      "Iteration 154, loss = 0.20926056\n",
      "Iteration 155, loss = 0.20916412\n",
      "Iteration 156, loss = 0.20886497\n",
      "Iteration 157, loss = 0.20890573\n",
      "Iteration 158, loss = 0.20905336\n",
      "Iteration 159, loss = 0.20891550\n",
      "Iteration 160, loss = 0.20806821\n",
      "Iteration 161, loss = 0.20821500\n",
      "Iteration 162, loss = 0.20812881\n",
      "Iteration 163, loss = 0.20793363\n",
      "Iteration 164, loss = 0.20830546\n",
      "Iteration 165, loss = 0.20788173\n",
      "Iteration 166, loss = 0.20828337\n",
      "Iteration 167, loss = 0.20790440\n",
      "Iteration 168, loss = 0.20769921\n",
      "Iteration 169, loss = 0.20796869\n",
      "Iteration 170, loss = 0.20768383\n",
      "Iteration 171, loss = 0.20702371\n",
      "Iteration 172, loss = 0.20668956\n",
      "Iteration 173, loss = 0.20727074\n",
      "Iteration 174, loss = 0.20687124\n",
      "Iteration 175, loss = 0.20674002\n",
      "Iteration 176, loss = 0.20678186\n",
      "Iteration 177, loss = 0.20639517\n",
      "Iteration 178, loss = 0.20638051\n",
      "Iteration 179, loss = 0.20656421\n",
      "Iteration 180, loss = 0.20669316\n",
      "Iteration 181, loss = 0.20621176\n",
      "Iteration 182, loss = 0.20625906\n",
      "Iteration 183, loss = 0.20642645\n",
      "Iteration 184, loss = 0.20599385\n",
      "Iteration 185, loss = 0.20627266\n",
      "Iteration 186, loss = 0.20575210\n",
      "Iteration 187, loss = 0.20536522\n",
      "Iteration 188, loss = 0.20563231\n",
      "Iteration 189, loss = 0.20551789\n",
      "Iteration 190, loss = 0.20557647\n",
      "Iteration 191, loss = 0.20508113\n",
      "Iteration 192, loss = 0.20550124\n",
      "Iteration 193, loss = 0.20548041\n",
      "Iteration 194, loss = 0.20510689\n",
      "Iteration 195, loss = 0.20541760\n",
      "Iteration 196, loss = 0.20561590\n",
      "Iteration 197, loss = 0.20500773\n",
      "Iteration 198, loss = 0.20503471\n",
      "Iteration 199, loss = 0.20453318\n",
      "Iteration 200, loss = 0.20485839\n",
      "Iteration 201, loss = 0.20476835\n",
      "Iteration 202, loss = 0.20444600\n",
      "Iteration 203, loss = 0.20467096\n",
      "Iteration 204, loss = 0.20471424\n",
      "Iteration 205, loss = 0.20424513\n",
      "Iteration 206, loss = 0.20388159\n",
      "Iteration 207, loss = 0.20417760\n",
      "Iteration 208, loss = 0.20438920\n",
      "Iteration 209, loss = 0.20398346\n",
      "Iteration 210, loss = 0.20403748\n",
      "Iteration 211, loss = 0.20412805\n",
      "Iteration 212, loss = 0.20332986\n",
      "Iteration 213, loss = 0.20389601\n",
      "Iteration 214, loss = 0.20343786\n",
      "Iteration 215, loss = 0.20327175\n",
      "Iteration 216, loss = 0.20335941\n",
      "Iteration 217, loss = 0.20325577\n",
      "Iteration 218, loss = 0.20366239\n",
      "Iteration 219, loss = 0.20332807\n",
      "Iteration 220, loss = 0.20319252\n",
      "Iteration 221, loss = 0.20326720\n",
      "Iteration 222, loss = 0.20300950\n",
      "Iteration 223, loss = 0.20292468\n",
      "Iteration 224, loss = 0.20309919\n",
      "Iteration 225, loss = 0.20279964\n",
      "Iteration 226, loss = 0.20274986\n",
      "Iteration 227, loss = 0.20274970\n",
      "Iteration 228, loss = 0.20234719\n",
      "Iteration 229, loss = 0.20278408\n",
      "Iteration 230, loss = 0.20229626\n",
      "Iteration 231, loss = 0.20210955\n",
      "Iteration 232, loss = 0.20246000\n",
      "Iteration 233, loss = 0.20259077\n",
      "Iteration 234, loss = 0.20225369\n",
      "Iteration 235, loss = 0.20239662\n",
      "Iteration 236, loss = 0.20223546\n",
      "Iteration 237, loss = 0.20217928\n",
      "Iteration 238, loss = 0.20183836\n",
      "Iteration 239, loss = 0.20238352\n",
      "Iteration 240, loss = 0.20182922\n",
      "Iteration 241, loss = 0.20194079\n",
      "Iteration 242, loss = 0.20138878\n",
      "Iteration 243, loss = 0.20231154\n",
      "Iteration 244, loss = 0.20222456\n",
      "Iteration 245, loss = 0.20180336\n",
      "Iteration 246, loss = 0.20155728\n",
      "Iteration 247, loss = 0.20125758\n",
      "Iteration 248, loss = 0.20186535\n",
      "Iteration 249, loss = 0.20123999\n",
      "Iteration 250, loss = 0.20094966\n",
      "Iteration 251, loss = 0.20095546\n",
      "Iteration 252, loss = 0.20130804\n",
      "Iteration 253, loss = 0.20128721\n",
      "Iteration 254, loss = 0.20099278\n",
      "Iteration 255, loss = 0.20101142\n",
      "Iteration 256, loss = 0.20121314\n",
      "Iteration 257, loss = 0.20125311\n",
      "Iteration 258, loss = 0.20081131\n",
      "Iteration 259, loss = 0.20182815\n",
      "Iteration 260, loss = 0.20055319\n",
      "Iteration 261, loss = 0.20121934\n",
      "Iteration 262, loss = 0.20072888\n",
      "Iteration 263, loss = 0.20069506\n",
      "Iteration 264, loss = 0.20091276\n",
      "Iteration 265, loss = 0.20099200\n",
      "Iteration 266, loss = 0.20053595\n",
      "Iteration 267, loss = 0.20025689\n",
      "Iteration 268, loss = 0.20096547\n",
      "Iteration 269, loss = 0.20096473\n",
      "Iteration 270, loss = 0.20040208\n",
      "Iteration 271, loss = 0.20072589\n",
      "Iteration 272, loss = 0.20090973\n",
      "Iteration 273, loss = 0.20049079\n",
      "Iteration 274, loss = 0.20060138\n",
      "Iteration 275, loss = 0.20008449\n",
      "Iteration 276, loss = 0.19988060\n",
      "Iteration 277, loss = 0.20036895\n",
      "Iteration 278, loss = 0.20016154\n",
      "Iteration 279, loss = 0.20037936\n",
      "Iteration 280, loss = 0.20007194\n",
      "Iteration 281, loss = 0.20006748\n",
      "Iteration 282, loss = 0.19979173\n",
      "Iteration 283, loss = 0.20001958\n",
      "Iteration 284, loss = 0.19956854\n",
      "Iteration 285, loss = 0.20011793\n",
      "Iteration 286, loss = 0.19964316\n",
      "Iteration 287, loss = 0.19978330\n",
      "Iteration 288, loss = 0.20005587\n",
      "Iteration 289, loss = 0.19988165\n",
      "Iteration 290, loss = 0.19993285\n",
      "Iteration 291, loss = 0.20043426\n",
      "Iteration 292, loss = 0.19967493\n",
      "Iteration 293, loss = 0.19969378\n",
      "Iteration 294, loss = 0.19934540\n",
      "Iteration 295, loss = 0.19985120\n",
      "Iteration 296, loss = 0.19968709\n",
      "Iteration 297, loss = 0.19986156\n",
      "Iteration 298, loss = 0.19963241\n",
      "Iteration 299, loss = 0.19962820\n",
      "Iteration 300, loss = 0.19977335\n",
      "Iteration 301, loss = 0.19895754\n",
      "Iteration 302, loss = 0.19959282\n",
      "Iteration 303, loss = 0.19931440\n",
      "Iteration 304, loss = 0.19882148\n",
      "Iteration 305, loss = 0.19915036\n",
      "Iteration 306, loss = 0.19930610\n",
      "Iteration 307, loss = 0.19898820\n",
      "Iteration 308, loss = 0.19991352\n",
      "Iteration 309, loss = 0.19903124\n",
      "Iteration 310, loss = 0.19923404\n",
      "Iteration 311, loss = 0.19910922\n",
      "Iteration 312, loss = 0.19911775\n",
      "Iteration 313, loss = 0.19931946\n",
      "Iteration 314, loss = 0.19906703\n",
      "Iteration 315, loss = 0.19853571\n",
      "Iteration 316, loss = 0.19902020\n",
      "Iteration 317, loss = 0.19877831\n",
      "Iteration 318, loss = 0.19897297\n",
      "Iteration 319, loss = 0.19944668\n",
      "Iteration 320, loss = 0.19872869\n",
      "Iteration 321, loss = 0.19840975\n",
      "Iteration 322, loss = 0.19856487\n",
      "Iteration 323, loss = 0.19849274\n",
      "Iteration 324, loss = 0.19931890\n",
      "Iteration 325, loss = 0.19885364\n",
      "Iteration 326, loss = 0.19904276\n",
      "Iteration 327, loss = 0.19881756\n",
      "Iteration 328, loss = 0.19856421\n",
      "Iteration 329, loss = 0.19875526\n",
      "Iteration 330, loss = 0.19835041\n",
      "Iteration 331, loss = 0.19893854\n",
      "Iteration 332, loss = 0.19804454\n",
      "Iteration 333, loss = 0.19891470\n",
      "Iteration 334, loss = 0.19844293\n",
      "Iteration 335, loss = 0.19892245\n",
      "Iteration 336, loss = 0.19836361\n",
      "Iteration 337, loss = 0.19854284\n",
      "Iteration 338, loss = 0.19843085\n",
      "Iteration 339, loss = 0.19768967\n",
      "Iteration 340, loss = 0.19892160\n",
      "Iteration 341, loss = 0.19817151\n",
      "Iteration 342, loss = 0.19791868\n",
      "Iteration 343, loss = 0.19819152\n",
      "Iteration 344, loss = 0.19773648\n",
      "Iteration 345, loss = 0.19762686\n",
      "Iteration 346, loss = 0.19853426\n",
      "Iteration 347, loss = 0.19872869\n",
      "Iteration 348, loss = 0.19790633\n",
      "Iteration 349, loss = 0.19780255\n",
      "Iteration 350, loss = 0.19835074\n",
      "Iteration 351, loss = 0.19775049\n",
      "Iteration 352, loss = 0.19789580\n",
      "Iteration 353, loss = 0.19782327\n",
      "Iteration 354, loss = 0.19816857\n",
      "Iteration 355, loss = 0.19763436\n",
      "Iteration 356, loss = 0.19752993\n",
      "Iteration 357, loss = 0.19768890\n",
      "Iteration 358, loss = 0.19778159\n",
      "Iteration 359, loss = 0.19799079\n",
      "Iteration 360, loss = 0.19795389\n",
      "Iteration 361, loss = 0.19753481\n",
      "Iteration 362, loss = 0.19782172\n",
      "Iteration 363, loss = 0.19761947\n",
      "Iteration 364, loss = 0.19812970\n",
      "Iteration 365, loss = 0.19729362\n",
      "Iteration 366, loss = 0.19737282\n",
      "Iteration 367, loss = 0.19760411\n",
      "Iteration 368, loss = 0.19808751\n",
      "Iteration 369, loss = 0.19761450\n",
      "Iteration 370, loss = 0.19730247\n",
      "Iteration 371, loss = 0.19745617\n",
      "Iteration 372, loss = 0.19745743\n",
      "Iteration 373, loss = 0.19746700\n",
      "Iteration 374, loss = 0.19730882\n",
      "Iteration 375, loss = 0.19714392\n",
      "Iteration 376, loss = 0.19740779\n",
      "Iteration 377, loss = 0.19774682\n",
      "Iteration 378, loss = 0.19663180\n",
      "Iteration 379, loss = 0.19711552\n",
      "Iteration 380, loss = 0.19736221\n",
      "Iteration 381, loss = 0.19733955\n",
      "Iteration 382, loss = 0.19691675\n",
      "Iteration 383, loss = 0.19716656\n",
      "Iteration 384, loss = 0.19739156\n",
      "Iteration 385, loss = 0.19714599\n",
      "Iteration 386, loss = 0.19750276\n",
      "Iteration 387, loss = 0.19732054\n",
      "Iteration 388, loss = 0.19730986\n",
      "Iteration 389, loss = 0.19732988\n",
      "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(20, 20), max_iter=1500, tol=1e-05,\n",
       "              verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MLPClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(hidden_layer_sizes=(20, 20), max_iter=1500, tol=1e-05,\n",
       "              verbose=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(20, 20), max_iter=1500, tol=1e-05,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network = MLPClassifier(max_iter=1500, verbose=True, tol=0.0000100,solver = 'adam', activation = 'relu', hidden_layer_sizes = (20,20))\n",
    "neural_network.fit(X_credit_training, y_credit_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], shape=(6517,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = neural_network.predict(X_credit_test)\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0], shape=(6517,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_credit_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9222034678533068"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_credit_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9222034678533068"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = ConfusionMatrix(neural_network)\n",
    "cm.fit(X_credit_training, y_credit_training)\n",
    "cm.score(X_credit_test, y_credit_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95      5179\n",
      "           1       0.90      0.70      0.79      1338\n",
      "\n",
      "    accuracy                           0.92      6517\n",
      "   macro avg       0.91      0.84      0.87      6517\n",
      "weighted avg       0.92      0.92      0.92      6517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_credit_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
